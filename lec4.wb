@course{Math 1030}
@setchapter{4}
@chapter{Matrices}
The lecture is based on Beezer, A first course in Linear algebra. Ver 3.5 Downloadable at http://linear.ups.edu/download.htmlPrint version can be downloaded at http://linear.ups.edu/download/fcla-3.50-print.pdf

<br/>
<h5 class="notkw">Reference.</h5>
<ul>
<li>
Beezer, Ver 3.5 Subsection MVNSE (print version p17 - p21)
</li>
<li>
Strang, Sect 1.4
</li>
</ul>
@section{
Introduction
}
@itemize
@item
After solving a few systems of equations, you will recognize that it does not matter so much what we call our variables.
@item
A system in the variables $x_{1},\,x_{2},\,x_{3}$ would behave the same if we changed the names of the variables to $a,\,b,\,c$ and kept all the constants the same and in the same places.
@item
In this section, we will isolate the key bits of information about a system of equations into something called a <b>matrix</b>, and then use this matrix to systematically solve the equations. Along the way we will obtain one of our most important and useful computational tools.
@enditemize
@section{
Matrix and Vector Notation for Systems of Equations
}
@defn
@title{Matrix}
@label{M}
An $m\times n$ <b>matrix</b> is a rectangular layout of real numbers with $m$ rows and $n$ columns.
@itemize
@item
@newcol
Many people use large parentheses instead of brackets – the distinction is not important.
@endcol
@item
@newcol
Rows of a matrix are indexed from the top (with the first row at the top labeled "row 1"), and columns are indexed from the left (with the first column on left labeled "column 1").
@endcol
@item
@newcol
For a matrix $A$, the notation $\left[A\right]_{ij}$, or $A_{ij}$, $A_{i,j}$, refers to the number in row $i$ and column $j$ of $A$.
@endcol
@enditemize
@end
@eg
@newcol
\[B=\begin{bmatrix}-1&2&5&3\\
1&0&-6&1\\
-4&2&2&-2\end{bmatrix}\]
is a matrix with $m=3$ rows and $n=4$ columns. We can say that $\left[B\right]_{2,3}=-6$ while $\left[B\right]_{3,4}=-2$.
@endcol
@end
@slide
When we do equation operations on a system of equations, the names of the variables really are not very important. Whether we use $x_{1}$, $x_{2}$, $x_{3}$, or $a$, $b$, $c$, or $x$, $y$, $z$ does not matter so much. In this subsection we will describe some notation that will make it easier to describe linear systems, solve the systems and describe the solution sets.
@slide
@defn
@title{Column Vector}
@label{CV}
@itemize
@item
A <b>column vector</b> of <b>size</b> $m$ is an ordered list of $m$ numbers, which is written in order vertically from top to bottom. We often refer to a column vector as simply a <b>vector</b>.
@item
@newcol
In these notes,
a column vector are typically represented by a bold faced, lower-case Roman letter, e.g. $\mathbf{u}$, $\mathbf{v}$, $\mathbf{w}$, $\mathbf{x}$, $\mathbf{y}$, $\mathbf{z}$, etc.
@endcol
@item
@newcol
Some authors prefer representing vectors with arrows, such as $\vec{u}$. Writing by hand, some like to put arrows on top of the symbol, or a tilde underneath the symbol, as in $\underset{\sim}{\textstyle u}$, or a line under the symbol, as $\underline{\textstyle u}$.
@endcol
@item
@newcol
To refer to $i$-th <b>entry</b> or <b>component</b> of a vector $\mathbf{v}$, we write $\left[\mathbf{v}\right]_{i}$ or $\mathbf{v}_i$.
@endcol
@enditemize
@end
@defn
@title{ (Zero Column Vector).}
@label{ZCV}
@col
The <b>zero vector</b> of size $m$ is the column vector of size $m$ where each entry is the number zero,
\[\mathbf{0}=\begin{bmatrix}0\\
0\\
0\\
\vdots\\
0\end{bmatrix}\]
or defined much more compactly, $\left[\mathbf{0}\right]_{i}=0$ for $1\leq i\leq m$.
@end
@section{
Partition of Matrices
}
Sometimes we use horizontal or vertical lines to visually divide a matrix into different areas. (Mathematically it is still the same object.)
@eg
@newcol
The matrix
\[
\left[\begin{array}[]{ccccc}
1&2&3&4&3.5\\
0&-1&1&1.1&1\\
3&5.8&1&0&-3\\
1&8&0&0&7\end{array}\right]
\]
is same as:
\[
\left[\begin{array}[]{cccc|c}1&2&3&4&3.5\\
0&-1&1&1.1&1\\
3&5.8&1&0&-3\\
1&8&0&0&7\end{array}\right]
\;,
\left[\begin{array}[]{c|c|c|c|c}1&2&3&4&3.5\\
0&-1&1&1.1&1\\
3&5.8&1&0&-3\\
1&8&0&0&7\end{array}\right],
\]
\[
\left[\begin{array}[]{ccccc}1&2&3&4&3.5\\
0&-1&1&1.1&1\\
\hline 3&5.8&1&0&-3\\
1&8&0&0&7\end{array}\right],
\;
\left[\begin{array}[]{cc|ccc}1&2&3&4&3.5\\
0&-1&1&1.1&1\\
\hline 3&5.8&1&0&-3\\
1&8&0&0&7\end{array}\right],
\]
\[
\left[\begin{array}[]{cc|ccc}1&2&3&4&3.5\\
0&-1&1&1.1&1\\
\hline 3&5.8&1&0&-3\\
\hline 1&8&0&0&7\end{array}\right]
\]
@endcol
@end
@eg
@col
One can also form <b>augmented matrices</b> as follows:

@col
\[A=\begin{bmatrix}1&2\\
3&4\\
5&6\\
7&8\end{bmatrix},\,\,\,\mathbf{u}=\begin{bmatrix}9\\
10\\
11\\
12\end{bmatrix}\,\,\,\mathbf{v}=\begin{bmatrix}13\\
14\\
15\\
16\end{bmatrix},\]
\[[A|\mathbf{u}]=\left[\begin{array}[]{cc|c}1&2&9\\
3&4&10\\
5&6&11\\
6&8&12\end{array}\right]=\left[\begin{array}[]{ccc}1&2&9\\
3&4&10\\
5&6&11\\
6&8&12\end{array}\right],\]
\[[A|\mathbf{u}|\mathbf{v}]=\left[\begin{array}[]{cc|c|c}1&2&9&13\\
3&4&10&14\\
5&6&11&15\\
6&8&12&15\end{array}\right]=\left[\begin{array}[]{cccc}1&2&9&13\\
3&4&10&14\\
5&6&11&15\\
6&8&12&15\end{array}\right],\]
@end
@eg
@col
\[A=\begin{bmatrix}1&2\\
3&4\end{bmatrix},\,\,B=\begin{bmatrix}5&6&7\\
8&9&10\end{bmatrix},\]
\[C=\begin{bmatrix}11&12\\
13&14\\
15&16\end{bmatrix},D=\begin{bmatrix}21&22&23\\
24&25&26\\
27&28&29\end{bmatrix}.\]
\[[A|B]=\left[\begin{array}[]{cc|ccc}1&2&5&6&7\\
3&4&8&9&10\end{array}\right]=\left[\begin{array}[]{ccccc}1&2&5&6&7\\
3&4&8&9&10\end{array}\right],\]
\[\left[\begin{array}[]{c|c}A&B\\
\hline C&D\end{array}\right]=\left[\begin{array}[]{cc|ccc}1&2&5&6&7\\
3&4&8&9&10\\
\hline 11&12&21&22&23\\
13&14&24&25&26\\
15&16&27&28&29\end{array}\right]=\left[\begin{array}[]{ccccc}1&2&5&6&7\\
3&4&8&9&10\\
11&12&21&22&23\\
13&14&24&25&26\\
15&16&27&28&29\end{array}\right]\]
@end
@section{
Matrix Representations of Linear Systems
}
The following definitions are stated in the context of
the following system of linear equations:
\begin{align*}
a_{11}x_1+a_{12}x_2+a_{13}x_3+\dots+a_{1n}x_n&=b_1\\
a_{21}x_1+a_{22}x_2+a_{23}x_3+\dots+a_{2n}x_n&=b_2\\
a_{31}x_1+a_{32}x_2+a_{33}x_3+\dots+a_{3n}x_n&=b_3\\
\vdots&\\
a_{m1}x_1+a_{m2}x_2+a_{m3}x_3+\dots+a_{mn}x_n&=b_m
\end{align*}
@defn
@title{Coefficient Matrix}
@label{CM}
@col
The <b>coefficient matrix</b> is the $m\times n$ matrix:
\[A=\begin{bmatrix}a_{11}&a_{12}&a_{13}&\dots&a_{1n}\\
a_{21}&a_{22}&a_{23}&\dots&a_{2n}\\
a_{31}&a_{32}&a_{33}&\dots&a_{3n}\\
\vdots&\vdots&\vdots&\vdots&\vdots\\
a_{m1}&a_{m2}&a_{m3}&\dots&a_{mn}\\
\end{bmatrix}\]
@end
@defn
@title{Vector of Constants}
@label{VOC}
@col
The <b>vector of constants</b> is the column vector of size $m$
\[\mathbf{b}=\begin{bmatrix}b_{1}\\
b_{2}\\
b_{3}\\
\vdots\\
b_{m}\\
\end{bmatrix}\]
@end
@defn
@title{Solution Vector}
@label{SOLV}
@col
The <b>solution vector</b> is the column vector of size $n$
\[\mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
\vdots\\
x_{n}\\
\end{bmatrix}\]
@end
@defn
@title{Matrix Representation of a Linear System}
@label{MRLS}
@col
If $A$ is the coefficient matrix of a system of linear equations and $\mathbf{b}$ is the vector of constants, then we will write $\mathcal{LS}(A,\mathbf{b})$ as a shorthand expression for the system of linear equations, which we will refer to as the <b>matrix representation</b> of the linear system.
@end
@slide
@defn
@title{Augmented Matrix}
@label{AM}
Suppose we have a system of $m$ equations in $n$ variables, with coefficient matrix $A$ and vector of constants $\mathbf{b}$. Then the <b>augmented matrix</b> of the system of equations is the $m\times(n+1)$ matrix whose first $n$ columns are the columns of $A$ and whose last column ($n+1$) is the column vector $\mathbf{b}$. This matrix will be written as $\left[A|\mathbf{b}\right]$.
@end
@eg
@title{Notation for systems of linear equations}
@col
The system of linear equations
\[\displaystyle 2x_{1}+4x_{2}-3x_{3}+5x_{4}+x_{5}=9\]
\[\displaystyle 3x_{1}+x_{2}+\quad\quad x_{4}-3x_{5}=0\]
\[\displaystyle-2x_{1}+7x_{2}-5x_{3}+2x_{4}+2x_{5}=-3\]
has coefficient matrix:

@col
\[A=\left[\begin{array}[]{ccccc}2&4&-3&5&1\\
3&1&0&1&-3\\
-2&7&-5&2&2\end{array}\right]\]
and vector of constants:

@col
\[\mathbf{b}=\begin{bmatrix}9\\
0\\
-3\end{bmatrix}\]
and so will be referenced as $\mathcal{LS}(A, \mathbf{b})$.
The augmented matrix is
\[\left[A|\mathbf{b}\right]=\left[\begin{array}[]{ccccc|c}2&4&-3&5&1&9\\
3&1&0&1&-3&0\\
-2&7&-5&2&2&-3\end{array}\right]\]
@end
@section{
Row operations
}
An augmented matrix can be used to represent a system of linear equations and release us from writing out all the variables.
We have seen how certain operations we can perform on equations will preserve their solutions .
The next two definitions and the following theorem carry over these ideas to augmented matrices.
@defn
@title{Row Operations}
@label{RO}
The following three operations will transform an $m\times n$ matrix into a different matrix of the same size, and each is known as an <b>elementary row operation</b>.
@enumerate
@item
@col
Swap the locations of two rows.

<strong>Notation</strong>: $R_{i}\leftrightarrow R_{j}$

(Swap the location of rows $i$ and $j$.)
@item
@col
Multiply each entry of a single row by a nonzero number.

<strong>Notation</strong>: $\alpha R_{i}$

(Multiply row $i$ by the nonzero scalar $\alpha$.)
@item
@col
Multiply each entry of one row by some number, and add these values to the entries in the same columns of a second row. Leave the first row the same after this operation, but replace the second row by the new values.

<strong>Notation</strong>: $\alpha R_{i}+R_{j}$

(Multiply row $i$ by the scalar $\alpha$ and add to row $j$.)
@endenumerate
@end
@defn
@title{Row-Equivalent Matrices}
@label{REM}
@col
Two matrices, $A$ and $B$, are <b>row-equivalent</b> if one can be obtained from the other by a sequence of row operations.
@end
@remark
@col
Notice that each of the three row operations is reversible, so we do not have to be careful about the distinction between $A$ is row-equivalent to $B$ and $B$ is row-equivalent to $A$.
@end
@slide
@eg
The matrices:
\begin{align*}
A=\begin{bmatrix}
2&-1&3&4\\
5&2&-2&3\\
1&1&0&6
\end{bmatrix}
&&
B=\begin{bmatrix}
1&1&0&6\\
3&0&-2&-9\\
2&-1&3&4
\end{bmatrix}
\end{align*}
are row-equivalent, as can be seen from:

@col
@steps
\begin{align*}
& \begin{bmatrix}
2&-1&3&4\\
5&2&-2&3\\
1&1&0&6
\end{bmatrix}
\\
&
\\
@nstep{\xrightarrow{\rowopswap{1}{3}}}
\quad&
@nstep{\begin{bmatrix}
1&1&0&6\\
5&2&-2&3\\
2&-1&3&4
\end{bmatrix}
}
\\
&
\\
@nstep{
\xrightarrow{\rowopadd{-2}{1}{2}}
}
\quad&
@nstep{
\begin{bmatrix}
1&1&0&6\\
3&0&-2&-9\\
2&-1&3&4
\end{bmatrix}
}
\end{align*}
@endsteps
In fact, any pair of these three matrices are row-equivalent.
@end
@slide
@thm
@title{Row-Equivalent Matrices represent Equivalent Systems}
@label{REMES}
Suppose that $A$ and $B$ are row-equivalent augmented matrices. Then the systems of linear equations that they represent are equivalent systems.
@end
@proof @col
See Beezer, Theorem REMES (Ver 3.5 print version p.20)
@end
@col
With this theorem, we now have a strategy for solving a system of linear equations:
@enumerate
@item
@col
Begin with a system of equations, represent the system by an augmented matrix.
@item
@col
perform row operations (which will preserve solutions for the system) to get a ”simpler” augmented matrix
@item
@col
convert back to a ”simpler” system of equations and then solve that system, knowing that its solutions are those of the original system.
@endenumerate
@slide
@eg
Solve:
\begin{align*}
x_1+2x_2+2x_3&=4\\
x_1+3x_2+3x_3&=5\\
2x_1+6x_2+5x_3&=6
\end{align*}
@col
Form the augmented matrix:
\begin{align*}
A=
\left[
\begin{array}{ccc|c}
1&2&2&4\\
1&3&3&5\\
2&6&5&6
\end{array}
\right]
\end{align*}
@col
then apply row operations:
@steps
\begin{align*}
\xrightarrow{\rowopadd{-1}{1}{2}}
\quad
&
@nstep{
\left[
\begin{array}{ccc|c}
1&2&2&4\\
0&1&1&1\\
2&6&5&6
\end{array}
\right]
}
\\
&
\\
@nstep{\xrightarrow{\rowopadd{-2}{1}{3}}}
\quad
&
@nstep{
\left[
\begin{array}{ccc|c}
1&2&2&4\\
0&1&1&1\\
0&2&1&-2
\end{array}
\right]
}
\\
&
\\
@nstep{
\xrightarrow{\rowopadd{-2}{2}{3}}
}
\quad
&
@nstep{
\left[
\begin{array}{ccc|c}
1&2&2&4\\
0&1&1&1\\
0&0&-1&-4
\end{array}
\right]
}
\\
&
\\
@nstep{
\xrightarrow{\rowopmult{-1}{3}}
}
\quad
&
@nstep{
\left[
\begin{array}{ccc|c}
1&2&2&4\\
0&1& 1&1\\
0&0&1&4
\end{array}
\right]
}
\end{align*}
@endsteps

@col
So the matrix
\[
\left[
\begin{array}{ccc|c}
1&2&2&4\\
0&1& 1&1\\
0&0&1&4
\end{array}
\right]
\]
is row equivalent to $A$.
By the previous theorem (@ref{REMES}), the system of equations below has the same solution set as the original system of equations:

@col
\begin{align*}
x_1+2x_2+2x_3&=4\\
x_2+ x_3&=1\\
x_3&=4
\end{align*}
@col
The third equation requires that $x_{3}=4$ to be true. Making this substitution into equation 2 we arrive at $x_{2}=-3$, and finally, substituting these values of $x_{2}$ and $x_{3}$ into the first equation, we find that $x_{1}=2$.
@end
