@course{MATH 1030}
@setchapter{10}
@chapter{Linear Combinations}
<h5 class="notkw">Reference.</h5>
Beezer, Ver 3.5 Section LC (print version p65 - p81)Strang: Section 2.3

<h5 class="notkw">Exercise.</h5> Exercises with solutions can be downloaded at http://linear.ups.edu/download/fcla-3.50-solution-manual.pdf

Section LC (p.32-33) C40, C41, M10, M11  
@section{Linear Combinations}
@label{LC}
@defn
@title{Linear Combination of Column Vectors}
@label{LCCV}
Given $n$ vectors $\mathbf{u}_{1},\,\mathbf{u}_{2},\,\mathbf{u}_{3},\,\ldots,\,\mathbf{u}_{n}$ in ${\mathbb{R}}^{m}$
and $n$ scalars $\alpha_{1},\,\alpha_{2},\,\alpha_{3},\,\ldots,\,\alpha_{n}$,
their @keyword{linear combination} is the vector:
\begin{align*}
\displaystyle \alpha_{1}\mathbf{u}_{1}+\alpha_{2}\mathbf{u}_{2}+\alpha_{3}\mathbf{u}_{3}+\cdots+\alpha_{n}\mathbf{u}_{n}
\end{align*}
in $\mathbb{R}^{m}$.  
@end
@eg
@label{TLC}
<strong>Two linear combinations in ${\mathbb{R}}^{6}$</strong>

@newcol
Suppose that:
\[
\alpha_{1}=1 \quad \alpha_{2}=-4 \quad \alpha_{3}=2 \quad \alpha_{4}=-1
\]
and
\begin{align*}
\displaystyle\mathbf{u}_{1}&\displaystyle=\begin{bmatrix}2\\
4\\
-3\\
1\\
2\\
9\end{bmatrix}&\displaystyle\mathbf{u}_{2}&\displaystyle=\begin{bmatrix}6\\
3\\
0\\
-2\\
1\\
4\end{bmatrix}&\displaystyle\mathbf{u}_{3}&\displaystyle=\begin{bmatrix}-5\\
2\\
1\\
1\\
-3\\
0\end{bmatrix}&\displaystyle\mathbf{u}_{4}&\displaystyle=\begin{bmatrix}3\\
2\\
-5\\
7\\
1\\
3\end{bmatrix}.
\end{align*}
The resulting linear combination is:

@col
@steps
\begin{multline*}
\displaystyle\alpha_{1}\mathbf{u_{1}}+\alpha_{2}\mathbf{u_{2}}+\alpha_{3}\mathbf{u_{3}}+\alpha_{4}\mathbf{u_{4}}
\\
\class{steps}{\cssId{step0}{=
(1)\begin{bmatrix}2\\
4\\
-3\\
1\\
2\\
9\end{bmatrix}+(-4)\begin{bmatrix}6\\
3\\
0\\
-2\\
1\\
4\end{bmatrix}+(2)\begin{bmatrix}-5\\
2\\
1\\
1\\
-3\\
0\end{bmatrix}+(-1)\begin{bmatrix}3\\
2\\
-5\\
7\\
1\\
3\end{bmatrix}}}
\\
\class{steps}{\cssId{step1}{=
\begin{bmatrix}2\\
4\\
-3\\
1\\
2\\
9\end{bmatrix}+\begin{bmatrix}-24\\
-12\\
0\\
8\\
-4\\
-16\end{bmatrix}+\begin{bmatrix}-10\\
4\\
2\\
2\\
-6\\
0\end{bmatrix}+\begin{bmatrix}-3\\
-2\\
5\\
-7\\
-1\\
-3\end{bmatrix}}}\class{steps}{\cssId{step2}{=
\begin{bmatrix}-35\\
-6\\
4\\
4\\
-9\\
-10\end{bmatrix}}}
\end{multline*}

@endsteps

@col
A different linear combination, but with the same set of vectors, can be formed with different scalars. Taking
\[
\displaystyle\beta_{1}=3 \quad \beta_{2}=0 \quad \beta_{3}=5 \quad \beta_{4}=-1
\]
we can form the linear combination:  
@steps
\begin{multline*}
\displaystyle\beta_{1}\mathbf{u_{1}}+\beta_{2}\mathbf{u_{2}}+\beta_{3}\mathbf{u_{3}}+\beta_{4}\mathbf{u_{4}}
\\
\class{steps}{\cssId{step0}{=(3)\begin{bmatrix}2\\
4\\
-3\\
1\\
2\\
9\end{bmatrix}+(0)\begin{bmatrix}6\\
3\\
0\\
-2\\
1\\
4\end{bmatrix}+(5)\begin{bmatrix}-5\\
2\\
1\\
1\\
-3\\
0\end{bmatrix}+(-1)\begin{bmatrix}3\\
2\\
-5\\
7\\
1\\
3\end{bmatrix}}}
\\
\class{steps}{\cssId{step1}{=\begin{bmatrix}6\\
12\\
-9\\
3\\
6\\
27\end{bmatrix}+\begin{bmatrix}0\\
0\\
0\\
0\\
0\\
0\end{bmatrix}+\begin{bmatrix}-25\\
10\\
5\\
5\\
-15\\
0\end{bmatrix}+\begin{bmatrix}-3\\
-2\\
5\\
-7\\
-1\\
-3\end{bmatrix}}}\class{steps}{\cssId{step2}{=\begin{bmatrix}-22\\
20\\
1\\
1\\
-10\\
24\end{bmatrix}.}}
\end{multline*}

@endsteps
@col
Notice how we could keep our set of vectors fixed but use a different set of scalars to construct different vectors.
Can you create the following vector $\mathbf{w}$ with a suitable choice of four scalars?
\begin{align*}
\displaystyle \mathbf{w}=\begin{bmatrix}13\\
15\\
5\\
-17\\
2\\
25\end{bmatrix}
\end{align*}  
@col
Going further, can you create any possible vector from ${\mathbb{R}}^{6}$ by choosing the proper scalars?  
@endcol
@end
@slide
@eg
The system of linear equation:
\begin{align*}
\displaystyle-7x_{1}-6x_{2}-12x_{3}&\displaystyle=-33 \\
\displaystyle 5x_{1}+5x_{2}+7x_{3}&\displaystyle=24 \\
\displaystyle x_{1}+4x_{3}&\displaystyle=5
\end{align*}

or equivalently
\begin{align*}
\displaystyle \begin{bmatrix}-7x_{1}-6x_{2}-12x_{3}\\
5x_{1}+5x_{2}+7x_{3}\\
x_{1}+4x_{3}\end{bmatrix}=\begin{bmatrix}-33\\
24\\
5\end{bmatrix},
\end{align*}

can be rewritten as:

@newcol
\begin{align*}
\displaystyle \begin{bmatrix}-7x_{1}\\
5x_{1}\\
x_{1}\end{bmatrix}+\begin{bmatrix}-6x_{2}\\
5x_{2}\\
0x_{2}\end{bmatrix}+\begin{bmatrix}-12x_{3}\\
7x_{3}\\
4x_{3}\end{bmatrix}=\begin{bmatrix}-33\\
24\\
5\end{bmatrix}
\end{align*}
or:

@col
\begin{align*}
\displaystyle x_{1}\begin{bmatrix}-7\\
5\\
1\end{bmatrix}+x_{2}\begin{bmatrix}-6\\
5\\
0\end{bmatrix}+x_{3}\begin{bmatrix}-12\\
7\\
4\end{bmatrix}=\begin{bmatrix}-33\\
24\\
5\end{bmatrix}.
\end{align*}

The solution is:

@col
\[
x_{1}=-3 \quad x_{2}=5 \quad x_{3}=2.
\]  
@col
So, in the context of this example, we can express the fact that these values of the variables are a solution by writing a linear combination:
\begin{align*}
\displaystyle (-3)\begin{bmatrix}-7\\
5\\
1\end{bmatrix}+(5)\begin{bmatrix}-6\\
5\\
0\end{bmatrix}+(2)\begin{bmatrix}-12\\
7\\
4\end{bmatrix}=\begin{bmatrix}-33\\
24\\
5\end{bmatrix}
\end{align*}  
@col
Furthermore, these are the only three scalars that will accomplish this equality, since they come from a unique solution.

@col
Notice how the three vectors in this example are the columns of the coefficient matrix of the system of equations. This is our first hint of the important interplay between the vectors that form the columns of a matrix, and the matrix itself.  
@endcol
@end
@slide
@eg
@skip
The system of linear equations
\begin{align*}
\displaystyle x_{1}-x_{2}+2x_{3}&\displaystyle=1 \\
\displaystyle 2x_{1}+x_{2}+x_{3}&\displaystyle=8 \\
\displaystyle x_{1}+x_{2}&\displaystyle=5
\end{align*}
can be written as:

@newcol
\begin{align*}
\displaystyle \begin{bmatrix}x_{1}-x_{2}+2x_{3}\\
2x_{1}+x_{2}+x_{3}\\
x_{1}+x_{2}\end{bmatrix}=\begin{bmatrix}1\\
8\\
5\end{bmatrix}.
\end{align*}
This vector equation is equivalent to:

@col
\begin{align*}
\displaystyle x_{1}\begin{bmatrix}1\\
2\\
1\end{bmatrix}+x_{2}\begin{bmatrix}-1\\
1\\
1\end{bmatrix}+x_{3}\begin{bmatrix}2\\
1\\
0\end{bmatrix}=\begin{bmatrix}1\\
8\\
5\end{bmatrix}.
\end{align*}

@col
Row-reducing the augmented matrix for the system leads to the conclusion that the system is consistent and has free variables, hence infinitely many solutions. So for example, the two solutions:
\begin{align*}
x_{1}&=2 &\quad& x_{2}=3 &\quad& x_{3}&=1 \\
x_{1}&=3 &\quad& x_{2}=2 &\quad& x_{3}&=0
\end{align*}
can be used together to say that:

@col
\begin{align*}
\displaystyle (2)\begin{bmatrix}1\\
2\\
1\end{bmatrix}+(3)\begin{bmatrix}-1\\
1\\
1\end{bmatrix}+(1)\begin{bmatrix}2\\
1\\
0\end{bmatrix}=\begin{bmatrix}1\\
8\\
5\end{bmatrix}=(3)\begin{bmatrix}1\\
2\\
1\end{bmatrix}+(2)\begin{bmatrix}-1\\
1\\
1\end{bmatrix}+(0)\begin{bmatrix}2\\
1\\
0\end{bmatrix}.
\end{align*}

@col
Ignore the middle of this equation, and move all the terms to the left-hand side:
\begin{align*}
\displaystyle (2)\begin{bmatrix}1\\
2\\
1\end{bmatrix}+(3)\begin{bmatrix}-1\\
1\\
1\end{bmatrix}+(1)\begin{bmatrix}2\\
1\\
0\end{bmatrix}+(-3)\begin{bmatrix}1\\
2\\
1\end{bmatrix}+(-2)\begin{bmatrix}-1\\
1\\
1\end{bmatrix}+(-0)\begin{bmatrix}2\\
1\\
0\end{bmatrix}=\begin{bmatrix}0\\
0\\
0\end{bmatrix}.
\end{align*}

@col
Regrouping gives:
\begin{align*}
\displaystyle (-1)\begin{bmatrix}1\\
2\\
1\end{bmatrix}+(1)\begin{bmatrix}-1\\
1\\
1\end{bmatrix}+(1)\begin{bmatrix}2\\
1\\
0\end{bmatrix}=\begin{bmatrix}0\\
0\\
0\end{bmatrix}.
\end{align*}

@col
Notice that the three vectors on the left hand side are the columns of the coefficient matrix for the system of equations. This equality says that there is a linear combination of those columns that equals the vector of all zeros. Give it some thought, but this says that:
\begin{align*}
\displaystyle x_{1}=-1&\quad&\displaystyle x_{2}=1&\quad&\displaystyle x_{3}=1
\end{align*}
is a nontrivial solution to the homogeneous system of equations with the coefficient matrix of the original system. In particular, this demonstrates that this coefficient matrix is singular.  
@endcol
@end
@slide
@thm
@title{Solutions to Linear Systems are Linear Combinations}
@label{SLSLC}
Denote the columns of the $m\times n$ matrix $A$ as vectors $\mathbf{A}_{1},\,\mathbf{A}_{2},\,\mathbf{A}_{3},\,\ldots,\,\mathbf{A}_{n}$. Then $\mathbf{x}\in{\mathbb{R}}^{n}$ is a solution to the linear system of equations $\mathcal{LS}({A},{\mathbf{b}})$ if and only if $\mathbf{b}$ is equal to the linear combination of the columns of $A$ formed with the entries of $\mathbf{x}$,
\begin{align*}
\displaystyle \left[\mathbf{x}\right]_{1}\mathbf{A}_{1}+\left[\mathbf{x}\right]_{2}\mathbf{A}_{2}+\left[\mathbf{x}\right]_{3}\mathbf{A}_{3}+\cdots+\left[\mathbf{x}\right]_{n}\mathbf{A}_{n}=\mathbf{b}
\end{align*}  
@end
@proof
@newcol
If $\mathbf{x}\in{\mathbb{R}}^{n}$ is a solution of $\mathcal{LS}({A},{\mathbf{b}})$, then
\begin{align*}
\displaystyle \mathbf{b}=A\mathbf{x}=\left[\mathbf{x}\right]_{1}\mathbf{A}_{1}+\left[\mathbf{x}\right]_{2}\mathbf{A}_{2}+\left[\mathbf{x}\right]_{3}\mathbf{A}_{3}+\cdots+\left[\mathbf{x}\right]_{n}\mathbf{A}_{n}.
\end{align*}  
@col
Hence $\mathbf{b}$ is a linear combination of the columns of $A$.

@col
Conversely, if $\mathbf{b}$ is a linear combinations of the columns of $A$, say:
\begin{align*}
\displaystyle \mathbf{b}=\left[\mathbf{x}\right]_{1}\mathbf{A}_{1}+\left[\mathbf{x}\right]_{2}\mathbf{A}_{2}+\left[\mathbf{x}\right]_{3}\mathbf{A}_{3}+\cdots+\left[\mathbf{x}\right]_{n}\mathbf{A}_{n},
\end{align*}  
@col
then
\begin{align*}
\displaystyle \mathbf{b}=A\mathbf{x}.
\end{align*}  
@col
So $\mathbf{x}$ is a solution of $\mathcal{LS}({A},{\mathbf{b}})$.  
@qed
@endcol
@end
@slide
<strong>Computational question</strong>: Determine if $\mathbf{u}$ is a linear combination of $\mathbf{v}_{1},\ldots,\mathbf{v}_{n}$. That is, determine whether or not the system of linear equations:
\begin{align*}
\displaystyle x_{1}\mathbf{v}_{1}+\cdots+x_{n}\mathbf{v}_{n}=\mathbf{u}
\end{align*}
has a solution. The augmented matrix is:
\begin{align*}
\displaystyle [\mathbf{v}_{1}|\cdots|\mathbf{v}_{n}|\mathbf{u}].
\end{align*}
Then we can solve the system of linear questions by the technique you learned.  
@eg
@newcol
Let
\begin{align*}
\displaystyle \mathbf{u} =
\begin{bmatrix}1\\
1\\
3\end{bmatrix},\quad
\mathbf{v}_{1}=\begin{bmatrix}1\\
2\\
3\end{bmatrix},
\mathbf{v}_{2}=\begin{bmatrix}-1\\
1\\
0\end{bmatrix},
\mathbf{v}_{3}=\begin{bmatrix}2\\
1\\
3\end{bmatrix},
\mathbf{v}_{4}=\begin{bmatrix}-1\\
0\\
1\end{bmatrix}.
\end{align*} <ol class="ltx_enumerate">
<li class="ltx_item">

Determine if $\mathbf{u}$ is a linear combination of $\{\mathbf{v}_{1},\mathbf{v}_{2},\mathbf{v}_{3}\}$.
If yes, find the linear combination. </li>
<li class="ltx_item">

Determine if $\mathbf{u}$ is a linear combination of $\{\mathbf{v}_{1},\mathbf{v}_{2},\mathbf{v}_{3},\mathbf{v}_{4}\}$.
If yes, find the linear combination. </li></ol>
@endcol
@end
@sol
@newcol
<ol class="ltx_enumerate">
<li class="ltx_item">
@col
To determine if $\mathbf{u}$ is a linear combination of $\{\mathbf{v}_{1},\mathbf{v}_{2},\mathbf{v}_{3}\}$,
we need to solve
\begin{align*}
\displaystyle x_{1}\mathbf{v}_{1}+x_{2}\mathbf{v}_{2}+x_{3}\mathbf{v}_{3}=\mathbf{u},
\end{align*}  
@col
i.e.
\begin{align*}
\displaystyle x_{1}-x_{2}+2x_{3}&\displaystyle=1 \\
\displaystyle 2x_{1}+x+2+x_{3}&\displaystyle=1 \\
\displaystyle 3x_{1}+3x_{3}&\displaystyle=3.
\end{align*}  
@col
The augmented matrix is
\begin{align*}
\displaystyle \left[\begin{array}[]{ccc|c}1&-1&2&1\\
2&1&1&1\\
3&0&3&3\end{array}\right]\xrightarrow{\operatorname{RREF}}\left[\begin{array}[]{ccc|c}1&0&1&0\\
0&1&-1&0\\
0&0&0&1\\
\end{array}\right].
\end{align*}  
@col
Because the last column of the RREF is a pivot column, the system of linear equations is not solvable.
Hence $\mathbf{u}$ is not a linear combination of $\{\mathbf{v}_{1},\mathbf{v}_{2},\mathbf{v}_{3}\}$. </li>
<li class="ltx_item">
@col
To determine if $\mathbf{u}$ is a linear combination of $\{\mathbf{v}_{1},\mathbf{v}_{2},\mathbf{v}_{3},\mathbf{v}_{4}\}$,
we need to solve
\begin{align*}
\displaystyle x_{1}\mathbf{v}_{1}+x_{2}\mathbf{v}_{2}+x_{3}\mathbf{v}_{3}+x_{4}\mathbf{v}_{4}=\mathbf{u}.
\end{align*}  
@col
The augmented matrix is:
\begin{align*}
\displaystyle [\mathbf{v}_{1}|\mathbf{v}_{2}|\mathbf{v}_{3}|\mathbf{v}_{4}|\mathbf{u}]=\left[\begin{array}[]{cccc|c}1&-1&2&-1&1\\
2&1&1&0&1\\
3&0&3&1&3\\
\end{array}\right].
\end{align*}  
@col
Using the standard method, we find one solution (there are infinitely many):
\begin{align*}
\displaystyle x_{1}=\frac{5}{6}
&\quad&
x_{2}=-\frac{2}{3}
&\quad&
x_{3}=0
&\quad&
x_{4}=\frac{1}{2}
\end{align*}  
@col
i.e.
\begin{align*}
\displaystyle \mathbf{u}=\frac{5}{6}\mathbf{v}_{1}-\frac{2}{3}\mathbf{v}_{2}+\frac{1}{2}\mathbf{v}_{4}.
\end{align*} </li></ol>
@endcol
@end
@section{Vector Form of Solution Sets}
@label{VFSS}
@eg
Consider the linear system
\begin{align*}
\displaystyle 2x_{1}+x_{2}+7x_{3}-7x_{4}&\displaystyle=8 \\
\displaystyle-3x_{1}+4x_{2}-5x_{3}-6x_{4}&\displaystyle=-12 \\
\displaystyle x_{1}+x_{2}+4x_{3}-5x_{4}&\displaystyle=4.
\end{align*}  
@newcol
Row-reducing the augmented matrix yields
\begin{align*}
\displaystyle \begin{bmatrix}\boxed{1}&0&3&-2&4\\
0&\boxed{1}&1&-3&0\\
0&0&0&0&0\end{bmatrix}
\end{align*}  
@col
from which we see that there are $r=2$ pivot columns. Also, $D=\{1,\,2\}$, so that the dependent variables are $x_{1}$ and $x_{2}$, and $F=\{3,\,4,\,5\}$, so that the free variables are $x_{3}$ and $x_{4}$. We will express a generic solution for the system by two slightly different methods, though both arrive at the same conclusion.

Rearranging each equation represented in the row-reduced form of the augmented matrix by solving for the dependent variable in each row yields the vector equality,
\begin{align*}
\displaystyle\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\end{bmatrix}&\displaystyle=\begin{bmatrix}4-3x_{3}+2x_{4}\\
-x_{3}+3x_{4}\\
x_{3}\\
x_{4}\end{bmatrix}\\
\\
&\displaystyle=\begin{bmatrix}4\\
0\\
0\\
0\end{bmatrix}+\begin{bmatrix}-3x_{3}\\
-x_{3}\\
x_{3}\\
0\end{bmatrix}+\begin{bmatrix}2x_{4}\\
3x_{4}\\
0\\
x_{4}\end{bmatrix} \\
&\displaystyle=\begin{bmatrix}4\\
0\\
0\\
0\end{bmatrix}+x_{3}\begin{bmatrix}-3\\
-1\\
1\\
0\end{bmatrix}+x_{4}\begin{bmatrix}2\\
3\\
0\\
1\end{bmatrix}.
\end{align*}

We will develop the same linear combination a bit quicker, using three steps. While the method above is instructive, the method below will be our preferred approach.

Step 1. Write the vector of variables as a fixed vector plus a linear combination of $n-r$ vectors, using the free variables as the scalars:
\begin{align*}
\displaystyle \mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\end{bmatrix}=\begin{bmatrix}
\;\\
\;\\
\;\\
\end{bmatrix}+x_{3}\begin{bmatrix}
\;\\
\;\\
\;\\
\end{bmatrix}+x_{4}\begin{bmatrix}
\;\\
\;\\
\;\\
\end{bmatrix}
\end{align*}

Step 2. Use 0’s and 1’s to ensure equality for the entries of the vectors with indices in $F$ (corresponding to the free variables):
\begin{align*}
\displaystyle \mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\end{bmatrix}=\begin{bmatrix}\\
\\
0\\
0\end{bmatrix}+x_{3}\begin{bmatrix}\\
\\
1\\
0\end{bmatrix}+x_{4}\begin{bmatrix}\\
\\
0\\
1\end{bmatrix}.
\end{align*}

Step 3. For each dependent variable, use the augmented matrix to formulate an equation expressing the dependent variable as a constant plus a linear combination of the free variables. Convert this equation into entries of the vectors that ensure equality for each dependent variable, one at a time.
\begin{align*}
\displaystyle x_{1}=4-3x_{3}+2x_{4}&\displaystyle\Rightarrow&\displaystyle\mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\end{bmatrix}=\begin{bmatrix}4\\
\\
0\\
0\end{bmatrix}+x_{3}\begin{bmatrix}-3\\
\\
1\\
0\end{bmatrix}+x_{4}\begin{bmatrix}2\\
\\
0\\
1\end{bmatrix} \\
\displaystyle x_{2}=0-1x_{3}+3x_{4}&\displaystyle\Rightarrow&\displaystyle\mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\end{bmatrix}=\begin{bmatrix}4\\
0\\
0\\
0\end{bmatrix}+x_{3}\begin{bmatrix}-3\\
-1\\
1\\
0\end{bmatrix}+x_{4}\begin{bmatrix}2\\
3\\
0\\
1\end{bmatrix}
\end{align*}

While this form is useful for quickly creating solutions, it is even better because it tells us exactly what every solution looks like. We know the solution set is infinite, which is pretty big, but now we can say that a solution is some multiple of $\begin{bmatrix}-3\\
-1\\
1\\
0\end{bmatrix}$ plus a multiple of $\begin{bmatrix}2\\
3\\
0\\
1\end{bmatrix}$ plus the fixed vector $\begin{bmatrix}4\\
0\\
0\\
0\end{bmatrix}$. Period. So it only takes us three vectors to describe the entire infinite solution set, provided we also agree on how to combine the three vectors into a linear combination.  
@endcol
@end
@eg
@skip
@newcol
Consider a linear system of $m=5$ equations in $n=7$ variables, having the augmented matrix
\begin{align*}
\displaystyle A=\begin{bmatrix}2&1&-1&-2&2&1&5&21\\
1&1&-3&1&1&1&2&-5\\
1&2&-8&5&1&1&-6&-15\\
3&3&-9&3&6&5&2&-24\\
-2&-1&1&2&1&1&-9&-30\end{bmatrix}.
\end{align*}

Row-reducing we obtain the matrix
\begin{align*}
\displaystyle B=\begin{bmatrix}\boxed{1}&0&2&-3&0&0&9&15\\
0&\boxed{1}&-5&4&0&0&-8&-10\\
0&0&0&0&\boxed{1}&0&-6&11\\
0&0&0&0&0&\boxed{1}&7&-21\\
0&0&0&0&0&0&0&0\end{bmatrix}
\end{align*}

and we see that there are $r=4$ pivot columns. Also, $D=\{1,\,2,\,5,\,6\}$ so the dependent variables are $x_{1},\,x_{2},\,x_{5},$ and $x_{6}$. Similarly, $F=\{3,\,4,\,7,\,8\}$ and the $n-r=3$ free variables are $x_{3},\,x_{4}$ and $x_{7}$. We will express a generic solution for the system by two different methods: both a decomposition and a construction.

Rearranging each equation represented in the row-reduced echelon form of the augmented matrix by solving for the dependent variable in each row yields the vector equality
\begin{align*}
\displaystyle\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}&\displaystyle=\begin{bmatrix}15-2x_{3}+3x_{4}-9x_{7}\\
-10+5x_{3}-4x_{4}+8x_{7}\\
x_{3}\\
x_{4}\\
11+6x_{7}\\
-21-7x_{7}\\
x_{7}\end{bmatrix}. \\
\\
&\displaystyle=\begin{bmatrix}15\\
-10\\
0\\
0\\
11\\
-21\\
0\end{bmatrix}+\begin{bmatrix}-2x_{3}\\
5x_{3}\\
x_{3}\\
0\\
0\\
0\\
0\end{bmatrix}+\begin{bmatrix}3x_{4}\\
-4x_{4}\\
0\\
x_{4}\\
0\\
0\\
0\end{bmatrix}+\begin{bmatrix}-9x_{7}\\
8x_{7}\\
0\\
0\\
6x_{7}\\
-7x_{7}\\
x_{7}\end{bmatrix} \\
&\displaystyle=\begin{bmatrix}15\\
-10\\
0\\
0\\
11\\
-21\\
0\end{bmatrix}+x_{3}\begin{bmatrix}-2\\
5\\
1\\
0\\
0\\
0\\
0\end{bmatrix}+x_{4}\begin{bmatrix}3\\
-4\\
0\\
1\\
0\\
0\\
0\end{bmatrix}+x_{7}\begin{bmatrix}-9\\
8\\
0\\
0\\
6\\
-7\\
1\end{bmatrix}.
\end{align*}

We will now develop the same linear combination a bit quicker, using three steps. While the method above is instructive, the method below will be our preferred approach.

Step 1. Write the vector of variables as a fixed vector, plus a linear combination of $n-r$ vectors, using the free variables as the scalars:
\begin{align*}
\displaystyle \mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}=\begin{bmatrix}\\
\;\\
\;\\
\;\\
\;\\
\;\\
\end{bmatrix}+x_{3}\begin{bmatrix}\\
\;\\
\;\\
\;\\
\;\\
\;\\
\end{bmatrix}+x_{4}\begin{bmatrix}\\
\;\\
\;\\
\;\\
\;\\
\;\\
\end{bmatrix}+x_{7}\begin{bmatrix}\\
\;\\
\;\\
\;\\
\;\\
\;\\
\end{bmatrix}
\end{align*}

Step 2. Use 0’s and 1’s to ensure equality for the entries of the vectors with indices in $F$ (corresponding to the free variables):
\begin{align*}
\displaystyle \mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}=\begin{bmatrix}\\
\\
0\\
0\\
\\
\\
0\end{bmatrix}+x_{3}\begin{bmatrix}\\
\\
1\\
0\\
\\
\\
0\end{bmatrix}+x_{4}\begin{bmatrix}\\
\\
0\\
1\\
\\
\\
0\end{bmatrix}+x_{7}\begin{bmatrix}\\
\\
0\\
0\\
\\
\\
1\end{bmatrix}
\end{align*}

Step 3. For each dependent variable, use the augmented matrix to formulate an equation expressing the dependent variable as a constant plus multiples of the free variables. Convert this equation into entries of the vectors that ensure equality for each dependent variable, one at a time.
\begin{align*}
\displaystyle x_{1}&\displaystyle=15-2x_{3}+3x_{4}-9x_{7}\ \Rightarrow \\
&\displaystyle\mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}=\begin{bmatrix}15\\
\\
0\\
0\\
\\
\\
0\end{bmatrix}+x_{3}\begin{bmatrix}-2\\
\\
1\\
0\\
\\
\\
0\end{bmatrix}+x_{4}\begin{bmatrix}3\\
\\
0\\
1\\
\\
\\
0\end{bmatrix}+x_{7}\begin{bmatrix}-9\\
\\
0\\
0\\
\\
\\
1\end{bmatrix} \\
\displaystyle x_{2}&\displaystyle=-10+5x_{3}-4x_{4}+8x_{7}\ \Rightarrow \\
&\displaystyle\mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}=\begin{bmatrix}15\\
-10\\
0\\
0\\
\\
\\
0\end{bmatrix}+x_{3}\begin{bmatrix}-2\\
5\\
1\\
0\\
\\
\\
0\end{bmatrix}+x_{4}\begin{bmatrix}3\\
-4\\
0\\
1\\
\\
\\
0\end{bmatrix}+x_{7}\begin{bmatrix}-9\\
8\\
0\\
0\\
\\
\\
1\end{bmatrix} \\
\displaystyle x_{5}&\displaystyle=11+6x_{7}\ \Rightarrow \\
&\displaystyle\mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}=\begin{bmatrix}15\\
-10\\
0\\
0\\
11\\
\\
0\end{bmatrix}+x_{3}\begin{bmatrix}-2\\
5\\
1\\
0\\
0\\
\\
0\end{bmatrix}+x_{4}\begin{bmatrix}3\\
-4\\
0\\
1\\
0\\
\\
0\end{bmatrix}+x_{7}\begin{bmatrix}-9\\
8\\
0\\
0\\
6\\
\\
1\end{bmatrix} \\
\displaystyle x_{6}&\displaystyle=-21-7x_{7}\ \Rightarrow \\
&\displaystyle\mathbf{x}=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}=\begin{bmatrix}15\\
-10\\
0\\
0\\
11\\
-21\\
0\end{bmatrix}+x_{3}\begin{bmatrix}-2\\
5\\
1\\
0\\
0\\
0\\
0\end{bmatrix}+x_{4}\begin{bmatrix}3\\
-4\\
0\\
1\\
0\\
0\\
0\end{bmatrix}+x_{7}\begin{bmatrix}-9\\
8\\
0\\
0\\
6\\
-7\\
1\end{bmatrix}
\end{align*}

This final form of a typical solution is especially pleasing and useful. For example, we can build solutions quickly by choosing values for our free variables, and then compute a linear combination. For example
\begin{align*}
\displaystyle x_{3}&\displaystyle=2,\,x_{4}=-4,\,x_{7}=3\quad\quad\Rightarrow \\
\displaystyle\mathbf{x}&\displaystyle=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}=\begin{bmatrix}15\\
-10\\
0\\
0\\
11\\
-21\\
0\end{bmatrix}+(2)\begin{bmatrix}-2\\
5\\
1\\
0\\
0\\
0\\
0\end{bmatrix}+(-4)\begin{bmatrix}3\\
-4\\
0\\
1\\
0\\
0\\
0\end{bmatrix}+(3)\begin{bmatrix}-9\\
8\\
0\\
0\\
6\\
-7\\
1\end{bmatrix}=\begin{bmatrix}-28\\
40\\
2\\
-4\\
29\\
-42\\
3\end{bmatrix}
\end{align*}

or perhaps,
\begin{align*}
\displaystyle x_{3}&\displaystyle=5,\,x_{4}=2,\,x_{7}=1\quad\quad\Rightarrow \\
\displaystyle\mathbf{x}&\displaystyle=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}=\begin{bmatrix}15\\
-10\\
0\\
0\\
11\\
-21\\
0\end{bmatrix}+(5)\begin{bmatrix}-2\\
5\\
1\\
0\\
0\\
0\\
0\end{bmatrix}+(2)\begin{bmatrix}3\\
-4\\
0\\
1\\
0\\
0\\
0\end{bmatrix}+(1)\begin{bmatrix}-9\\
8\\
0\\
0\\
6\\
-7\\
1\end{bmatrix}=\begin{bmatrix}2\\
15\\
5\\
2\\
17\\
-28\\
1\end{bmatrix}
\end{align*}

or even,
\begin{align*}
\displaystyle x_{3}&\displaystyle=0,\,x_{4}=0,\,x_{7}=0\quad\quad\Rightarrow \\
\displaystyle\mathbf{x}&\displaystyle=\begin{bmatrix}x_{1}\\
x_{2}\\
x_{3}\\
x_{4}\\
x_{5}\\
x_{6}\\
x_{7}\end{bmatrix}=\begin{bmatrix}15\\
-10\\
0\\
0\\
11\\
-21\\
0\end{bmatrix}+(0)\begin{bmatrix}-2\\
5\\
1\\
0\\
0\\
0\\
0\end{bmatrix}+(0)\begin{bmatrix}3\\
-4\\
0\\
1\\
0\\
0\\
0\end{bmatrix}+(0)\begin{bmatrix}-9\\
8\\
0\\
0\\
6\\
-7\\
1\end{bmatrix}=\begin{bmatrix}15\\
-10\\
0\\
0\\
11\\
-21\\
0\end{bmatrix}.
\end{align*}

So we can compactly express all of the solutions to this linear system with just 4 fixed vectors, provided we agree how to combine them in a linear combinations to create solution vectors.

Suppose you were told that the vector $\mathbf{w}$ below was a solution to this system of equations. Could you turn the problem around and write $\mathbf{w}$ as a linear combination of the four vectors $\mathbf{c}$, $\mathbf{u}_{1}$, $\mathbf{u}_{2}$, $\mathbf{u}_{3}$?
\begin{align*}
\displaystyle\mathbf{w}&\displaystyle=\begin{bmatrix}100\\
-75\\
7\\
9\\
-37\\
35\\
-8\end{bmatrix}&\displaystyle\mathbf{c}&\displaystyle=\begin{bmatrix}15\\
-10\\
0\\
0\\
11\\
-21\\
0\end{bmatrix}&\displaystyle\mathbf{u}_{1}&\displaystyle=\begin{bmatrix}-2\\
5\\
1\\
0\\
0\\
0\\
0\end{bmatrix}&\displaystyle\mathbf{u}_{2}&\displaystyle=\begin{bmatrix}3\\
-4\\
0\\
1\\
0\\
0\\
0\end{bmatrix}&\displaystyle\mathbf{u}_{3}&\displaystyle=\begin{bmatrix}-9\\
8\\
0\\
0\\
6\\
-7\\
1\end{bmatrix}
\end{align*}  
@endcol
@end
@slide
@thm
@title{Vector Form of Solutions to Linear Systems}
@label{VFSLS}
Suppose that $\left[A|\mathbf{b}\right]$ is the augmented matrix for a consistent linear system $\mathcal{LS}({A},{\mathbf{b}})$ of $m$ equations in $n$ variables.
Let $B$ be a row-equivalent $m\times(n+1)$ matrix in reduced row-echelon form. Suppose that $B$ has $r$ pivot columns, with indices $D=\{d_{1},\,d_{2},\,d_{3},\,\ldots,\,d_{r}\}$, while the $n-r$ non-pivot columns have indices in $F=\{f_{1},\,f_{2},\,f_{3},\,\ldots,\,f_{n-r},\,n+1\}$. Define vectors $\mathbf{c}$, $\mathbf{u}_{j}$, $1\leq j\leq n-r$ of size $n$ by
\begin{align*}
\displaystyle\left[\mathbf{c}\right]_{i}&\displaystyle=\begin{cases}0&\text{if $i\in F$}\\
\left[B\right]_{k,n+1}&\text{if $i\in D$, $i=d_{k}$}\end{cases} \\
\displaystyle\left[\mathbf{u}_{j}\right]_{i}&\displaystyle=\begin{cases}1&\text{if $i\in F$, $i=f_{j}$}\\
0&\text{if $i\in F$, $i\neq f_{j}$}\\
-\left[B\right]_{k,f_{j}}&\text{if $i\in D$, $i=d_{k}$}\end{cases}.
\end{align*}

Then the set of solutions to the system of equations $\mathcal{LS}({A},{\mathbf{b}})$ is
\begin{align*}
\displaystyle S=\left\{\left.\mathbf{c}+\alpha_{1}\mathbf{u}_{1}+\alpha_{2}\mathbf{u}_{2}+\alpha_{3}\mathbf{u}_{3}+\cdots+\alpha_{n-r}\mathbf{u}_{n-r}\,\right|\,\alpha_{1},\,\alpha_{2},\,\alpha_{3},\,\ldots,\,\alpha_{n-r}\in{\mathbb{R}}^{\hbox{}}.\right\}
\end{align*}  
@end
@proof
<strong>You can skip this proof for now, as long as you understand the examples</strong>
@newcol
First, the equation $\mathcal{LS}({A},{\mathbf{b}})$ is equivalent to the linear system of equations that has the matrix $B$ as its augmented matrix.
So we need only show that $S$ is the solution set for the system with $B$ as its augmented matrix. The conclusion of this theorem is that the solution set is equal to the set $S$.

We begin by showing that every element of $S$ is indeed a solution to the system. Let $\alpha_{1},\,\alpha_{2},\,\alpha_{3},\,\ldots,\,\alpha_{n-r}$ be one choice of the scalars used to describe elements of $S$. So an arbitrary element of $S$, which we will consider as a proposed solution, is
\begin{align*}
\displaystyle \mathbf{x}=\mathbf{c}+\alpha_{1}\mathbf{u}_{1}+\alpha_{2}\mathbf{u}_{2}+\alpha_{3}\mathbf{u}_{3}+\cdots+\alpha_{n-r}\mathbf{u}_{n-r}.
\end{align*}

When $r+1\leq\ell\leq m$, row $\ell$ of the matrix $B$ is a zero row, so the equation represented by that row is always true, no matter which solution vector we propose. So concentrate on rows representing equations $1\leq\ell\leq r$. We evaluate equation $\ell$ of the system represented by $B$ with the proposed solution vector $\mathbf{x}$ and refer to the value of the left-hand side of the equation as $\beta_{\ell}$:
\begin{align*}
\displaystyle \beta_{\ell}=\left[B\right]_{\ell 1}\left[\mathbf{x}\right]_{1}+\left[B\right]_{\ell 2}\left[\mathbf{x}\right]_{2}+\left[B\right]_{\ell 3}\left[\mathbf{x}\right]_{3}+\cdots+\left[B\right]_{\ell n}\left[\mathbf{x}\right]_{n}
\end{align*}

Since $\left[B\right]_{\ell d_{i}}=0$ for all $1\leq i\leq r$, except that $\left[B\right]_{\ell d_{\ell}}=1$, we see that $\beta_{\ell}$ simplifies to
\begin{align*}
\displaystyle \beta_{\ell}=\left[\mathbf{x}\right]_{d_{\ell}}+\left[B\right]_{\ell f_{1}}\left[\mathbf{x}\right]_{f_{1}}+\left[B\right]_{\ell f_{2}}\left[\mathbf{x}\right]_{f_{2}}+\left[B\right]_{\ell f_{3}}\left[\mathbf{x}\right]_{f_{3}}+\cdots+\left[B\right]_{\ell f_{n-r}}\left[\mathbf{x}\right]_{f_{n-r}}.
\end{align*}

Notice that for $1\leq i\leq n-r$
\begin{align*}
\displaystyle\left[\mathbf{x}\right]_{f_{i}}&\displaystyle=\left[\mathbf{c}\right]_{f_{i}}+\alpha_{1}\left[\mathbf{u}_{1}\right]_{f_{i}}+\alpha_{2}\left[\mathbf{u}_{2}\right]_{f_{i}}+\cdots+\alpha_{i}\left[\mathbf{u}_{i}\right]_{f_{i}}+\cdots+\alpha_{n-r}\left[\mathbf{u_{n-r}}\right]_{f_{i}} \\
&\displaystyle=0+\alpha_{1}(0)+\alpha_{2}(0)+\cdots+\alpha_{i}(1)+\cdots+\alpha_{n-r}(0) \\
&\displaystyle=\alpha_{i}.
\end{align*}

So $\beta_{\ell}$ simplifies further, and we expand the first term
\begin{align*}
\displaystyle\beta_{\ell}&\displaystyle=\left[\mathbf{x}\right]_{d_{\ell}}+\left[B\right]_{\ell f_{1}}\alpha_{1}+\left[B\right]_{\ell f_{2}}\alpha_{2}+\left[B\right]_{\ell f_{3}}\alpha_{3}+\cdots+\left[B\right]_{\ell f_{n-r}}\alpha_{n-r} \\
&\displaystyle=\left[\mathbf{c}+\alpha_{1}\mathbf{u}_{1}+\alpha_{2}\mathbf{u}_{2}+\alpha_{3}\mathbf{u}_{3}+\cdots+\alpha_{n-r}\mathbf{u}_{n-r}\right]_{d_{\ell}}+ \\
&\displaystyle\quad\quad\left[B\right]_{\ell f_{1}}\alpha_{1}+\left[B\right]_{\ell f_{2}}\alpha_{2}+\left[B\right]_{\ell f_{3}}\alpha_{3}+\cdots+\left[B\right]_{\ell f_{n-r}}\alpha_{n-r} \\
&\displaystyle=\left[\mathbf{c}\right]_{d_{\ell}}+\alpha_{1}\left[\mathbf{u}_{1}\right]_{d_{\ell}}+\alpha_{2}\left[\mathbf{u}_{2}\right]_{d_{\ell}}+\alpha_{3}\left[\mathbf{u}_{3}\right]_{d_{\ell}}+\cdots+\alpha_{n-r}\left[\mathbf{u_{n-r}}\right]_{d_{\ell}}+ \\
&\displaystyle\quad\quad\left[B\right]_{\ell f_{1}}\alpha_{1}+\left[B\right]_{\ell f_{2}}\alpha_{2}+\left[B\right]_{\ell f_{3}}\alpha_{3}+\cdots+\left[B\right]_{\ell f_{n-r}}\alpha_{n-r} \\
&\displaystyle=\left[B\right]_{\ell,{n+1}}+ \\
&\displaystyle\quad\quad\alpha_{1}(-\left[B\right]_{\ell f_{1}})+\alpha_{2}(-\left[B\right]_{\ell f_{2}})+\alpha_{3}(-\left[B\right]_{\ell f_{3}})+\cdots+\alpha_{n-r}(-\left[B\right]_{\ell f_{n-r}})+ \\
&\displaystyle\quad\quad\left[B\right]_{\ell f_{1}}\alpha_{1}+\left[B\right]_{\ell f_{2}}\alpha_{2}+\left[B\right]_{\ell f_{3}}\alpha_{3}+\cdots+\left[B\right]_{\ell f_{n-r}}\alpha_{n-r} \\
&\displaystyle=\left[B\right]_{\ell,{n+1}}.
\end{align*}

So $\beta_{\ell}$ began as the left-hand side of equation $\ell$ of the system represented by $B$ and we now know it equals $\left[B\right]_{\ell,{n+1}}$, the constant term for equation $\ell$ of this system. So the arbitrarily chosen vector from $S$ makes every equation of the system true, and therefore is a solution to the system. So all the elements of $S$ are solutions to the system.

For the second half of the proof, assume that $\mathbf{x}$ is a solution vector for the system having $B$ as its augmented matrix. For convenience and clarity, denote the entries of $\mathbf{x}$ by $x_{i}$. In other words, $x_{i}=\left[\mathbf{x}\right]_{i}$. We desire to show that this solution vector is also an element of the set $S$. Begin with the observation that the entries of a solution vector make equation $\ell$ of the system true for all $1\leq\ell\leq m$:

\begin{align*}
\displaystyle \left[B\right]_{\ell,1}x_{1}+\left[B\right]_{\ell,2}x_{2}+\left[B\right]_{\ell,3}x_{3}+\cdots+\left[B\right]_{\ell,n}x_{n}=\left[B\right]_{\ell,n+1}
\end{align*}

When $\ell\leq r$, the pivot columns of $B$ have zero entries in row $\ell$ with the exception of column $d_{\ell}$, which will contain a $1$. So for $1\leq\ell\leq r$, equation $\ell$ simplifies to
\begin{align*}
\displaystyle 1x_{d_{\ell}}+\left[B\right]_{\ell,f_{1}}x_{f_{1}}+\left[B\right]_{\ell,f_{2}}x_{f_{2}}+\left[B\right]_{\ell,f_{3}}x_{f_{3}}+\cdots+\left[B\right]_{\ell,f_{n-r}}x_{f_{n-r}}=\left[B\right]_{\ell,n+1}.
\end{align*}

This allows us to write,
\begin{align*}
\displaystyle\left[\mathbf{x}\right]_{d_{\ell}}&\displaystyle=x_{d_{\ell}} \\
&\displaystyle=\left[B\right]_{\ell,n+1}-\left[B\right]_{\ell,f_{1}}x_{f_{1}}-\left[B\right]_{\ell,f_{2}}x_{f_{2}}-\left[B\right]_{\ell,f_{3}}x_{f_{3}}-\cdots-\left[B\right]_{\ell,f_{n-r}}x_{f_{n-r}} \\
&\displaystyle=\left[\mathbf{c}\right]_{d_{\ell}}+x_{f_{1}}\left[\mathbf{u}_{1}\right]_{d_{\ell}}+x_{f_{2}}\left[\mathbf{u}_{2}\right]_{d_{\ell}}+x_{f_{3}}\left[\mathbf{u}_{3}\right]_{d_{\ell}}+\cdots+x_{f_{n-r}}\left[\mathbf{u}_{n-r}\right]_{d_{\ell}} \\
&\displaystyle=\left[\mathbf{c}+x_{f_{1}}\mathbf{u}_{1}+x_{f_{2}}\mathbf{u}_{2}+x_{f_{3}}\mathbf{u}_{3}+\cdots+x_{f_{n-r}}\mathbf{u}_{n-r}\right]_{d_{\ell}}.
\end{align*}

This tells us that the entries of the solution vector $\mathbf{x}$ corresponding to dependent variables (indices in $D$) are equal to those of a vector in the set $S$. We still need to check the other entries of the solution vector $\mathbf{x}$ corresponding to the free variables (indices in $F$) to see if they are equal to the entries of the same vector in the set $S$. To this end, suppose $i\in F$ and $i=f_{j}$. Then
\begin{align*}
\displaystyle\left[\mathbf{x}\right]_{i}&\displaystyle=x_{i}=x_{f_{j}} \\
&\displaystyle=0+0x_{f_{1}}+0x_{f_{2}}+0x_{f_{3}}+\cdots+0x_{f_{j-1}}+1x_{f_{j}}+0x_{f_{j+1}}+\cdots+0x_{f_{n-r}} \\
&\displaystyle=\left[\mathbf{c}\right]_{i}+x_{f_{1}}\left[\mathbf{u}_{1}\right]_{i}+x_{f_{2}}\left[\mathbf{u}_{2}\right]_{i}+x_{f_{3}}\left[\mathbf{u}_{3}\right]_{i}+\cdots+x_{f_{j}}\left[\mathbf{u}_{j}\right]_{i}+\cdots+x_{f_{n-r}}\left[\mathbf{u}_{n-r}\right]_{i} \\
&\displaystyle=\left[\mathbf{c}+x_{f_{1}}\mathbf{u}_{1}+x_{f_{2}}\mathbf{u}_{2}+\cdots+x_{f_{n-r}}\mathbf{u}_{n-r}\right]_{i}.
\end{align*}

So entries of
$\mathbf{x}$ and $\mathbf{c}+x_{f_{1}}\mathbf{u}_{1}+x_{f_{2}}\mathbf{u}_{2}+\cdots+x_{f_{n-r}}\mathbf{u}_{n-r}$
are equal and therefore they are equal vectors. Since $x_{f_{1}},\,x_{f_{2}},\,x_{f_{3}},\,\ldots,\,x_{f_{n-r}}$ are scalars, this shows us that $\mathbf{x}$ qualifies for membership in $S$. So the set $S$ contains all of the solutions to the system.  
@qed
@endcol
@end


<!--DELIMITER-->
